# Tiny LLM zh

## 1.ç®€ä»‹

æœ¬é¡¹ç›®æ—¨åœ¨æ„å»ºä¸€ä¸ªå°å‚æ•°é‡çš„ä¸­æ–‡è¯­è¨€å¤§æ¨¡å‹ï¼Œç”¨äºå¿«é€Ÿå…¥é—¨å­¦ä¹ å¤§æ¨¡å‹ç›¸å…³çŸ¥è¯†ï¼Œå¦‚æœæ­¤é¡¹ç›®å¯¹ä½ æœ‰ç”¨ï¼Œå¯ä»¥ç‚¹ä¸€ä¸‹startï¼Œè°¢è°¢ï¼

æ¨¡å‹æ¶æ„ï¼šæ•´ä½“æ¨¡å‹æ¶æ„é‡‡ç”¨å¼€æºé€šç”¨æ¶æ„ï¼ŒåŒ…æ‹¬ï¼šRMSNormï¼ŒRoPEï¼ŒMHAç­‰

å®ç°ç»†èŠ‚ï¼šå®ç°å¤§æ¨¡å‹ä¸¤é˜¶æ®µè®­ç»ƒåŠåç»­äººç±»å¯¹é½ï¼Œå³ï¼šé¢„è®­ç»ƒ(PTM) -> æŒ‡ä»¤å¾®è°ƒ(SFT) -> äººç±»å¯¹é½(RLHF, DPO) -> æµ‹è¯„ã€‚

æœ¬é¡¹ç›®ä¸»è¦æœ‰ä¸‰ä¸ªåˆ†æ”¯ï¼Œæ¨èå­¦ä¹  ä¸»åˆ†æ”¯ï¼Œå…·ä½“åŒºåˆ«å¦‚ä¸‹ï¼š

- [llama2_torch](https://github.com/wdndev/tiny-llm-zh/tree/llama2_torch) ï¼š æ¨¡å‹æ¶æ„é‡‡ç”¨åŸç‰ˆ Llama2 æ¶æ„ï¼Œåªæ˜¯å°†éƒ¨åˆ†çš„è¾“å…¥è¾“å‡ºä¿®æ”¹ä¸ºé€‚åˆè®­ç»ƒçš„æ ¼å¼ï¼›
- `main`   `tiny_llm` ï¼š å¯¹é½å¼€æºç¤¾åŒºæ¨¡å‹ï¼Œä½¿ç”¨Transformersåº“æ„å»ºåº•å±‚æ¨¡å‹ï¼Œä¹Ÿä½¿ç”¨Transformersåº“è¿›è¡Œå¤šå¡å¤šæœºè®­ç»ƒï¼›
- [tiny_llm_moe](https://github.com/wdndev/tiny-llm-zh/tree/tiny_llm_moe) ï¼š åœ¨`tiny_llm`çš„åŸºç¡€ä¸Šï¼Œä¿®æ”¹ `MLP`å±‚ä¸ºMoEæ¨¡å‹ï¼Œä½¿ç”¨Transformersåº“è¿›è¡Œå¤šå¡å¤šæœºè®­ç»ƒã€‚

æ³¨æ„ï¼šå› èµ„æºé™åˆ¶ï¼Œæœ¬é¡¹ç›®çš„ç¬¬ä¸€è¦åŠ¡æ˜¯èµ°é€šå¤§æ¨¡å‹æ•´ä¸ªæµç¨‹ï¼Œè€Œä¸æ˜¯è°ƒæ•™æ¯”è¾ƒå¥½çš„æ•ˆæœï¼Œæ•…è¯„æµ‹ç»“æœåˆ†æ•°è¾ƒä½ï¼Œéƒ¨åˆ†ç”Ÿæˆé”™è¯¯ã€‚

## 2.å¿«é€Ÿå¼€å§‹

æ¨¡å‹å·²æ‰˜ç®¡åœ¨ [Huggingface](https://huggingface.co/wdndev/tiny_llm_sft_92m) å’Œ [ModeScope](https://www.modelscope.cn/models/wdndev/tiny_llm_sft_92m) ä¸­ï¼Œå¯è¿è¡Œä»£ç è‡ªåŠ¨ä¸‹è½½ã€‚

å»ºè®®ä½¿ç”¨ Huggingface åœ¨çº¿åŠ è½½æ¨¡å‹ï¼Œå¦‚æœè¿è¡Œä¸äº†ï¼Œåœ¨è¯• ModeScope ï¼›å¦‚æœéœ€è¦æœ¬åœ°è¿è¡Œï¼Œä¿®æ”¹`model_id`ä¸­çš„è·¯å¾„ä¸ºæœ¬åœ°ç›®å½•ï¼Œå³å¯è¿è¡Œã€‚

#### ğŸ¤— Huggingface

```python
from transformers import AutoTokenizer, AutoModelForCausalLM

model_id = "wdndev/tiny_llm_sft_92m"

tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(model_id, device_map="auto", trust_remote_code=True)

sys_text = "ä½ æ˜¯ç”±wdndevå¼€å‘çš„ä¸ªäººåŠ©æ‰‹ã€‚"
# user_text = "ä¸–ç•Œä¸Šæœ€å¤§çš„åŠ¨ç‰©æ˜¯ä»€ä¹ˆï¼Ÿ"
# user_text = "ä»‹ç»ä¸€ä¸‹åˆ˜å¾·åã€‚"
user_text = "ä»‹ç»ä¸€ä¸‹ä¸­å›½ã€‚"
input_txt = "\n".join(["<|system|>", sys_text.strip(), 
                        "<|user|>", user_text.strip(), 
                        "<|assistant|>"]).strip() + "\n"

model_inputs = tokenizer(input_txt, return_tensors="pt").to(model.device)
generated_ids = model.generate(model_inputs.input_ids, max_new_tokens=200)
generated_ids = [
    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
]
response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
print(response)
```

#### ğŸ¤– ModeScope

```python
from modelscope import AutoModelForCausalLM, AutoTokenizer

model_id = "wdndev/tiny_llm_sft_92m"

tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(model_id, device_map="auto", trust_remote_code=True)

sys_text = "ä½ æ˜¯ç”±wdndevå¼€å‘çš„ä¸ªäººåŠ©æ‰‹ã€‚"
# user_text = "ä¸–ç•Œä¸Šæœ€å¤§çš„åŠ¨ç‰©æ˜¯ä»€ä¹ˆï¼Ÿ"
# user_text = "ä»‹ç»ä¸€ä¸‹åˆ˜å¾·åã€‚"
user_text = "ä»‹ç»ä¸€ä¸‹ä¸­å›½ã€‚"
input_txt = "\n".join(["<|system|>", sys_text.strip(), 
                        "<|user|>", user_text.strip(), 
                        "<|assistant|>"]).strip() + "\n"

model_inputs = tokenizer(input_txt, return_tensors="pt").to(model.device)
generated_ids = model.generate(model_inputs.input_ids, max_new_tokens=200)
generated_ids = [
    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
]
response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
print(response)
```


ç”Ÿæˆæ•ˆæœ
```bash
é—®ï¼šä¸–ç•Œä¸Šæœ€å¤§çš„åŠ¨ç‰©æ˜¯ä»€ä¹ˆï¼Ÿ
ç­”ï¼šç›®å‰å·²çŸ¥æœ€å¤§çš„åŠ¨ç‰©æ˜¯è“é²¸ï¼ˆBalaenoptera musculusï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªåºå¤§çš„å“ºä¹³åŠ¨ç‰©ï¼Œå±äºé¡»é²¸äºšç›®ã€é¡»é²¸ç§‘ä¸­çš„æœ€å¤§ç‰©ç§ã€‚è“é²¸çš„èº«é•¿å¯è¾¾30ç±³ä»¥ä¸Šï¼Œä½“é‡å¯è¾¾175å¨ã€‚å®ƒä»¬åœ¨æµ·æ´‹ä¸­ç”Ÿæ´»ï¼Œä¸»è¦ä»¥æµ®æ¸¸ç”Ÿç‰©ä¸ºé£Ÿï¼Œå¦‚ç”²å£³ç±»åŠ¨ç‰©å’Œå°å‹é±¼ç±»ç­‰ã€‚ç”±äºå…¶å·¨å¤§çš„ä½“å‹å’Œå¤æ‚çš„ç”Ÿæ€ç¾¤è½ï¼Œè“é²¸æˆä¸ºæµ·æ´‹æ—…æ¸¸çš„çƒ­é—¨æ™¯ç‚¹ä¹‹ä¸€ã€‚

é—®ï¼šä»‹ç»ä¸€ä¸‹åˆ˜å¾·åã€‚
ç­”ï¼šåˆ˜å¾·åæ˜¯ä¸€ä½é¦™æ¸¯æµè¡Œæ­Œæ‰‹ã€æ¼”å‘˜å’Œå¯¼æ¼”ï¼Œä»–åœ¨éŸ³ä¹ç•Œçš„è´¡çŒ®éå¸¸å·¨å¤§ã€‚ä»–æ˜¯åè¯­ä¹å›å†å²ä¸Šæœ€ä¼Ÿå¤§çš„è‰ºäººä¹‹ä¸€ï¼Œä»£è¡¨ä½œå“åŒ…æ‹¬ã€Šçˆ±æˆ‘èº«ä½“ã€‹å’Œã€Šè‚¥çš‚æ³¡ã€‹ã€‚ä»–ä¹Ÿç»å¸¸å‚æ¼”ç”µå½±å’Œç”µè§†å‰§ï¼Œå¹¶åœ¨ç”µè§†ä¸Šå—åˆ°å¥½è¯„ã€‚

é—®ï¼šä»‹ç»ä¸€ä¸‹ä¸­å›½ã€‚
ç­”ï¼šä¸­å›½æ˜¯ä½äºä¸œäºšçš„å¤§é™†ï¼Œè¢«æ¬§æ´²ä»¥åŠäºšæ´²å’Œå…¶ä»–å¤§é™†æ‰€åŒ…å›´ã€‚å®ƒæ˜¯ä¸­å›½ç¬¬äºŒå¤§æ–‡æ˜å’Œä¸–ç•Œä¸Šæœ€å¤§çš„ç»æµä½“ä¹‹ä¸€ã€‚ä¸­å›½çš„å†å²å¯ä»¥è¿½æº¯åˆ°å…¬å…ƒå‰5000å¹´å·¦å³ï¼Œä»å¤è‡³ä»Šéƒ½æœ‰å…¶ç‹¬ç‰¹çš„æ–‡åŒ–å’Œè¯­è¨€ä¼ æ‰¿è€…ã€‚

```









